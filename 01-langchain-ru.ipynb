{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30822,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Введение\n\nДобро пожаловать в краткое руководство по использованию возможностей LangChain! Этот урок познакомит вас с различными концепциями и инструментами, которые помогут эффективнее разрабатывать проекты на базе искусственного интеллекта.\n\nМы рассмотрим такие темы, как:\n\n- Установка библиотек.\n- Получение API-ключей OpenAI.\n- Генерация ответов с использованием языковой модели.\n- Создание цепочек (chains).\n- Добавление памяти в модели.\n- Использование векторных баз данных.\n- Практический пример работы с Deep Lake в качестве векторного хранилища.\n\nКроме того, мы изучим, как применять инструменты и агенты, такие как агент векторного хранилища. Благодаря лаконичным объяснениям и примерам кода, это руководство станет полезным ресурсом для новичков в LangChain или тех, кто хочет улучшить свои рабочие процессы в сфере ИИ.\n\nМы также рассмотрим использование различных инструментов, включая Google Search, и обсудим, как комбинировать их с подходящими агентами для достижения нужных результатов. Вы узнаете, как запускать и управлять этими агентами, которые выступают в роли координаторов, выбирая инструменты на основе полученных запросов.\n\n## Установка и API-ключи\n\nДля начала установите необходимые пакеты следующей командой:","metadata":{}},{"cell_type":"code","source":"pip -q install langchain==0.0.208 deeplake==3.9.27 openai==0.27.8 tiktoken  ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-04T23:03:24.960960Z","iopub.execute_input":"2025-02-04T23:03:24.961451Z","iopub.status.idle":"2025-02-04T23:03:29.340902Z","shell.execute_reply.started":"2025-02-04T23:03:24.961414Z","shell.execute_reply":"2025-02-04T23:03:29.339544Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Чтобы получить доступ к сервисам OpenAI:**\n\n1. Если у вас ещё нет аккаунта, зарегистрируйтесь на https://platform.openai.com/. Если аккаунт уже есть, перейдите к шагу 5.\n2. Заполните форму регистрации, указав имя, email и пароль.\n3. OpenAI отправит вам письмо с подтверждением. Перейдите по ссылке в письме.\n4. Подтвердите email и укажите номер телефона для верификации.\n5. Авторизуйтесь на https://platform.openai.com/.\n6. Перейдите в раздел API-ключей: https://platform.openai.com/account/api-keys.\n7. Нажмите Create new secret key, задайте ключу понятное имя и сохраните его.\n\nТеперь вы можете использовать возможности OpenAI в своих проектах","metadata":{}},{"cell_type":"code","source":"import os\nfrom kaggle_secrets import UserSecretsClient\n\nuser_secrets = UserSecretsClient()\n\nactiveloop_token = user_secrets.get_secret(\"ACTIVELOOP_TOKEN\")\nopenai_api_key = user_secrets.get_secret(\"OPENAI_API_KEY\")\n\nos.environ[\"ACTIVELOOP_TOKEN\"] = activeloop_token\nos.environ[\"OPENAI_API_KEY\"] = openai_api_key\n\nprint(\"Activeloop token exists:\", \"ACTIVELOOP_TOKEN\" in os.environ)\nprint(\"OpenAI key exists:\", \"OPENAI_API_KEY\" in os.environ)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-04T23:03:29.342532Z","iopub.execute_input":"2025-02-04T23:03:29.342843Z","iopub.status.idle":"2025-02-04T23:03:29.726403Z","shell.execute_reply.started":"2025-02-04T23:03:29.342816Z","shell.execute_reply":"2025-02-04T23:03:29.725034Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Вызов языковой модели (LLM)\n\nОсновная функция LangChain заключается в вызове языковой модели (LLM) с конкретным запросом. Чтобы продемонстрировать это, рассмотрим пример сервиса, который предлагает персонализированные программы тренировок на основе целей и предпочтений пользователя.\n\nСначала импортируем обёртку для работы с LLM:","metadata":{}},{"cell_type":"code","source":"from langchain.llms import OpenAI","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-02-04T23:03:44.640980Z","iopub.execute_input":"2025-02-04T23:03:44.641369Z","iopub.status.idle":"2025-02-04T23:03:47.975501Z","shell.execute_reply.started":"2025-02-04T23:03:44.641317Z","shell.execute_reply":"2025-02-04T23:03:47.974246Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Параметр temperature**\n\nЭтот параметр управляет случайностью выходных данных моделей OpenAI:\n\n- 0: вывод предсказуем, подходит для задач, требующих стабильности.\n- 1.0: вывод случайный и креативный, но редко рекомендуется для практических задач.\n- 0.70–0.90: баланс между надёжностью и креативностью, идеален для творческих задач.\n\nОптимальное значение подбирается экспериментально для каждого сценария. В примере ниже инициализируется модель GPT-3.5 Turbo:","metadata":{}},{"cell_type":"code","source":"llm = OpenAI(model=\"gpt-3.5-turbo-instruct\", temperature=0.9)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-04T23:03:53.700020Z","iopub.execute_input":"2025-02-04T23:03:53.700666Z","iopub.status.idle":"2025-02-04T23:03:53.724951Z","shell.execute_reply.started":"2025-02-04T23:03:53.700630Z","shell.execute_reply":"2025-02-04T23:03:53.722838Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Пример использования**\n\nЗапросим у модели персонализированную тренировку:","metadata":{}},{"cell_type":"code","source":"text = \"Suggest a personalized workout routine for someone looking to improve cardiovascular endurance and prefers outdoor activities.\"\nprint(llm(text))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-04T23:03:56.052001Z","iopub.execute_input":"2025-02-04T23:03:56.052416Z","iopub.status.idle":"2025-02-04T23:03:59.585131Z","shell.execute_reply.started":"2025-02-04T23:03:56.052336Z","shell.execute_reply":"2025-02-04T23:03:59.583991Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Цепочки (Chains) в LangChain\n\nЦепочка объединяет несколько компонентов для решения типовых задач. Самый популярный тип — LLMChain, который включает:\n\n- PromptTemplate (шаблон запроса)\n- Модель (LLM или ChatModel)\n- Опциональный парсер вывода\n\nКак работает LLMChain:\n\n1. Принимает входные переменные.\n2. Форматирует их в запрос с помощью PromptTemplate.\n3. Передаёт запрос модели.\n4. При наличии парсера — преобразует вывод модели в нужный формат.\n\n**Пример: генерация названия компании**\n\nСоздадим цепочку для генерации названия компании, производящей экологичные бутылки для воды:","metadata":{}},{"cell_type":"code","source":"from langchain.prompts import PromptTemplate\nfrom langchain.llms import OpenAI\nfrom langchain.chains import LLMChain\n\nllm = OpenAI(model=\"gpt-3.5-turbo-instruct\", temperature=0.9)\nprompt = PromptTemplate(\n    input_variables=[\"product\"],\n    template=\"What is a good name for a company that makes {product}?\",\n)\n\nchain = LLMChain(llm=llm, prompt=prompt)\n\n# Run the chain only specifying the input variable.\nprint(chain.run(\"eco-friendly water bottles\"))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-04T23:04:03.329768Z","iopub.execute_input":"2025-02-04T23:04:03.330128Z","iopub.status.idle":"2025-02-04T23:04:05.001125Z","shell.execute_reply.started":"2025-02-04T23:04:03.330095Z","shell.execute_reply":"2025-02-04T23:04:05.000052Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Память (Memory) в LangChain\n\nПамять в LangChain — это механизм, который сохраняет и управляет историей диалога между пользователем и ИИ. \n\nОна помогает поддерживать контекст и согласованность взаимодействия, позволяя модели генерировать более релевантные и точные ответы. \nНапример, ConversationBufferMemory выступает обёрткой вокруг ChatMessageHistory, извлекая сообщения и передавая их в цепочку для улучшения контекстной генерации.\n\n**Пример использования памяти:**","metadata":{}},{"cell_type":"code","source":"from langchain.llms import OpenAI\nfrom langchain.chains import ConversationChain\nfrom langchain.memory import ConversationBufferMemory\n\nllm = OpenAI(model=\"gpt-3.5-turbo-instruct\", temperature=0)\nconversation = ConversationChain(\n    llm=llm,\n    verbose=True,\n    memory=ConversationBufferMemory()\n)\n\n# Start the conversation\nconversation.predict(input=\"Tell me about yourself.\")\n\n# Continue the conversation\nconversation.predict(input=\"What can you do?\")\nconversation.predict(input=\"How can you help me with data analysis?\")\n\n# Display the conversation\nprint(conversation)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-04T23:04:12.075903Z","iopub.execute_input":"2025-02-04T23:04:12.076474Z","iopub.status.idle":"2025-02-04T23:04:15.878594Z","shell.execute_reply.started":"2025-02-04T23:04:12.076417Z","shell.execute_reply":"2025-02-04T23:04:15.877525Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Как это работает?**\n\n- В разделе Current conversation видно, как память сохраняет историю.\n- После каждого запроса пользователя диалог обновляется: добавляются реплики и ответы ИИ.\n- При генерации нового ответа модель использует эту историю как контекст, что повышает согласованность и релевантность ответов.\n\nТаким образом, память позволяет LangChain поддерживать длительные диалоги, учитывая предыдущие взаимодействия.","metadata":{}},{"cell_type":"markdown","source":"## Deep Lake VectorStore\nDeep Lake — это хранилище для эмбеддингов и их метаданных в контексте LLM-приложений. Оно позволяет выполнять гибридный поиск по эмбеддингам и атрибутам для эффективного извлечения данных. Интеграция с LangChain упрощает разработку и развёртывание приложений.\n\nПреимущества Deep Lake:\n\n- Мультимодальность: поддерживает хранение текстов, изображений, аудио, видео и их векторных представлений.\n- Серверless-архитектура: облачные датасеты можно создавать и управлять ими без настройки серверов.\n- Совместимость с ML-фреймворками: датасеты можно конвертировать в DataLoader для обучения моделей в PyTorch или TensorFlow.\n\n**Настройка API-токена Activeloop:**\n\n1. Зарегистрируйтесь на Activeloop.\n2. На главной странице нажмите Create API token.\n3. Укажите название токена и срок действия.\n4. Скопируйте токен и сохраните его в переменной окружения ACTIVELOOP_TOKEN:","metadata":{}},{"cell_type":"code","source":"os.environ[\"ACTIVELOOP_TOKEN\"] = activeloop_token","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-04T23:04:25.851946Z","iopub.execute_input":"2025-02-04T23:04:25.852297Z","iopub.status.idle":"2025-02-04T23:04:25.857121Z","shell.execute_reply.started":"2025-02-04T23:04:25.852265Z","shell.execute_reply":"2025-02-04T23:04:25.855879Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**⚠️ Важно:** Не храните токены в коде — это угроза безопасности. Используйте переменные окружения или защищённые конфиги.","metadata":{}},{"cell_type":"code","source":"!pip -q install deeplake==3.9.27  ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-04T21:23:45.223386Z","iopub.execute_input":"2025-02-04T21:23:45.223767Z","iopub.status.idle":"2025-02-04T21:23:49.473572Z","shell.execute_reply.started":"2025-02-04T21:23:45.223737Z","shell.execute_reply":"2025-02-04T21:23:49.472027Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Пример работы с Deep Lake:**","metadata":{}},{"cell_type":"code","source":"from langchain.embeddings.openai import OpenAIEmbeddings  \nfrom langchain.vectorstores import DeepLake  \nfrom langchain.text_splitter import RecursiveCharacterTextSplitter  \nfrom langchain.llms import OpenAI  \nfrom langchain.chains import RetrievalQA  \n\n# Инициализация моделей  \nllm = OpenAI(model=\"gpt-3.5-turbo-instruct\", temperature=0)  \nembeddings = OpenAIEmbeddings(model=\"text-embedding-ada-002\")  \n\n# Подготовка документов  \ntexts = [  \n    \"Napoleon Bonaparte was born in 15 August 1769\",  \n    \"Louis XIV was born in 5 September 1638\"  \n]  \ntext_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=0)  \ndocs = text_splitter.create_documents(texts)  \n\n# Создание датасета\nmy_activeloop_org_id = \"xmarva\"  \nmy_activeloop_dataset_name = \"langchain_course_from_zero_to_hero\"  \ndataset_path = f\"hub://{my_activeloop_org_id}/{my_activeloop_dataset_name}\"  \n\ndb = DeepLake(dataset_path=dataset_path, embedding_function=embeddings)  \n \ndb.add_documents(docs)  ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-04T23:04:31.132767Z","iopub.execute_input":"2025-02-04T23:04:31.133102Z","iopub.status.idle":"2025-02-04T23:05:08.394564Z","shell.execute_reply.started":"2025-02-04T23:04:31.133077Z","shell.execute_reply":"2025-02-04T23:05:08.393579Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Создание цепочки RetrievalQA:**\n\nRetrievalQA — это цепочка, которая объединяет два ключевых компонента:\n\n- Извлечение (Retrieval): Извлечение релевантных документов из векторной базы данных\n- Генерация (QuestionAnswering): Использование языковой модели для формирования ответа на основе найденных документов.\n\nchain_type=\"stuff\" — контекст из найденных документов \"вставляется\" прямо в промпт LLM.","metadata":{}},{"cell_type":"code","source":"retrieval_qa = RetrievalQA.from_chain_type(  \n    llm=llm,  \n    chain_type=\"stuff\",  \n    retriever=db.as_retriever()  \n)  ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-04T23:05:27.396875Z","iopub.execute_input":"2025-02-04T23:05:27.397239Z","iopub.status.idle":"2025-02-04T23:05:27.403010Z","shell.execute_reply.started":"2025-02-04T23:05:27.397207Z","shell.execute_reply":"2025-02-04T23:05:27.401531Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Инициализация агента с инструментом RetrievalQA:**\n\nАгент — это сущность, которая использует инструменты (tools) для выполнения задачи. RetrievalQA становится одним из таких инструментов.\n\n- Создаётся инструмент на основе RetrievalQA:\n- Указывается имя, описание, и функция (retrieval_qa.run).\n- Агент анализирует запрос и решает, какой инструмент использовать.\n- Результат работы инструмента передаётся в LLM для финального ответа.\n\nТип агента ZERO_SHOT_REACT_DESCRIPTION:\n\n- Агент не имеет памяти о предыдущих шагах.\n- Принимает решение на основе текущего запроса и описаний инструментов.\n- Формат ответа: Мысль → Действие → Наблюдение → Ответ.","metadata":{}},{"cell_type":"code","source":"from langchain.agents import initialize_agent, Tool  \nfrom langchain.agents import AgentType  \n\ntools = [  \n    Tool(  \n        name=\"Retrieval QA System\",  \n        func=retrieval_qa.run,  \n        description=\"Useful for answering questions.\"  \n    ),  \n]  \n\nagent = initialize_agent(  \n    tools,  \n    llm,  \n    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,  \n    verbose=True  \n)  \n\n# Запрос к агенту  \nresponse = agent.run(\"When was Napoleone born?\")  \nprint(response)  ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-04T23:05:32.432510Z","iopub.execute_input":"2025-02-04T23:05:32.432848Z","iopub.status.idle":"2025-02-04T23:05:35.438686Z","shell.execute_reply.started":"2025-02-04T23:05:32.432821Z","shell.execute_reply":"2025-02-04T23:05:35.437622Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Добавление новых данных в датасет**\n\nЧтобы векторная база (Deep Lake) могла отвечать на новые вопросы, в неё нужно добавлять актуальную информацию.\n\nПосле добавления данных пересоздайте цепочку RetrievalQA и агента, чтобы они учитывали обновлённые данные.\nЭмбеддинги для новых документов генерируются автоматически при вызове add_documents().","metadata":{}},{"cell_type":"code","source":"# Загрузка существующего датасета  \ndb = DeepLake(dataset_path=dataset_path, embedding_function=embeddings)  \n\n# Новые документы  \ntexts = [  \n    \"Lady Gaga was born in 28 March 1986\",  \n    \"Michael Jeffrey Jordan was born in 17 February 1963\"  \n]  \ndocs = text_splitter.create_documents(texts)  \n\n# Добавление в датасет  \ndb.add_documents(docs)  \n\n# Повторная инициализация агента  \nretrieval_qa = RetrievalQA.from_chain_type(  \n    llm=llm, chain_type=\"stuff\", retriever=db.as_retriever()  \n)  \n\ntools = [  \n    Tool(  \n        name=\"Retrieval QA System\",  \n        func=retrieval_qa.run,  \n        description=\"Useful for answering questions.\"  \n    ),  \n]  \n\nagent = initialize_agent(  \n    tools,  \n    llm,  \n    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,  \n    verbose=True  \n)  \n\n# Тестирование  \nresponse = agent.run(\"When was Michael Jordan born?\")  \nprint(response)  ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-04T23:05:40.775064Z","iopub.execute_input":"2025-02-04T23:05:40.775476Z","iopub.status.idle":"2025-02-04T23:06:19.341491Z","shell.execute_reply.started":"2025-02-04T23:05:40.775439Z","shell.execute_reply":"2025-02-04T23:06:19.340268Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Агенты в LangChain\n\nВ LangChain агенты — это высокоуровневые компоненты, которые используют языковые модели для определения последовательности действий. Действием может быть использование инструмента (например, поиск в Google) или возврат ответа пользователю. Инструменты — это функции для конкретных задач: поиск в интернете, запросы к базам данных, выполнение кода.\n\nАгенты работают по циклу:\n\n- Решение (LLM выбирает действие)\n- Выполнение действия (использует инструмент)\n- Анализ результата\n- Повторение до завершения задачи\n\n## Типы агентов в LangChain\n\n- Zero-shot-react-description: Выбирает инструменты на основе их описаний (без предварительного обучения).\n- React-docstore: Работает с документами через инструменты Search (поиск документа) и Lookup (поиск термина в документе).\n- Self-ask-with-search: Использует инструмент Intermediate Answer для поиска фактов (аналог Google Search).\n- Conversational-react-description: Для диалогов, использует память о предыдущих взаимодействиях.\n\n## Пример: Агент с Google Search\n\n1. Настройка переменных окружения. Установите GOOGLE_API_KEY и GOOGLE_CSE_ID для доступа к Google Search API. Инструкция здесь","metadata":{}},{"cell_type":"code","source":"google_cse_id = user_secrets.get_secret(\"GOOGLE_CSE_ID\")\nopenai_api_key = user_secrets.get_secret(\"GOOGLE_API_KEY\")\n\nos.environ[\"GOOGLE_CSE_ID\"] = google_cse_id\nos.environ[\"GOOGLE_API_KEY\"] = openai_api_key\n\nprint(\"GOOGLE_CSE token exists:\", \"GOOGLE_CSE_ID\" in os.environ)\nprint(\"GOOGLE_API exists:\", \"GOOGLE_API_KEY\" in os.environ)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-04T23:14:17.792506Z","iopub.execute_input":"2025-02-04T23:14:17.792896Z","iopub.status.idle":"2025-02-04T23:14:18.182283Z","shell.execute_reply.started":"2025-02-04T23:14:17.792862Z","shell.execute_reply":"2025-02-04T23:14:18.181172Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%pip -q install --upgrade --quiet  langchain-google-community","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-04T23:11:33.683924Z","iopub.execute_input":"2025-02-04T23:11:33.684315Z","iopub.status.idle":"2025-02-04T23:11:38.201966Z","shell.execute_reply.started":"2025-02-04T23:11:33.684281Z","shell.execute_reply":"2025-02-04T23:11:38.200511Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"search = GoogleSearchAPIWrapper()  # Автоматически использует GOOGLE_API_KEY и GOOGLE_CSE_ID  \n\ntools = [  \n    Tool(  \n        name=\"google-search\",  \n        func=search.run,  \n        description=\"Search Google for recent results\"  \n    )  \n]  \n\ntools[0].run(\"Obama's first name?\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-04T23:16:36.275493Z","iopub.execute_input":"2025-02-04T23:16:36.275852Z","iopub.status.idle":"2025-02-04T23:16:36.419176Z","shell.execute_reply.started":"2025-02-04T23:16:36.275826Z","shell.execute_reply":"2025-02-04T23:16:36.417457Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"2. Импорт модулей","metadata":{}},{"cell_type":"code","source":"from langchain.llms import OpenAI  \nfrom langchain.agents import AgentType, load_tools, initialize_agent, Tool  \nfrom langchain.utilities import GoogleSearchAPIWrapper  ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-04T23:17:01.430023Z","iopub.execute_input":"2025-02-04T23:17:01.430409Z","iopub.status.idle":"2025-02-04T23:17:01.435754Z","shell.execute_reply.started":"2025-02-04T23:17:01.430369Z","shell.execute_reply":"2025-02-04T23:17:01.434489Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"3. Инициализация модели","metadata":{}},{"cell_type":"code","source":"llm = OpenAI(model=\"gpt-3.5-turbo-instruct\", temperature=0)  # temperature=0 для точных ответов  ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-04T23:17:02.336384Z","iopub.execute_input":"2025-02-04T23:17:02.336765Z","iopub.status.idle":"2025-02-04T23:17:02.341798Z","shell.execute_reply.started":"2025-02-04T23:17:02.336734Z","shell.execute_reply":"2025-02-04T23:17:02.340601Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"4. Создание инструмента Google Search","metadata":{}},{"cell_type":"code","source":"search = GoogleSearchAPIWrapper()  # Автоматически использует GOOGLE_API_KEY и GOOGLE_CSE_ID  \n\ntools = [  \n    Tool(  \n        name=\"google-search\",  \n        func=search.run,  \n        description=\"Поиск в Google для ответов на вопросы о текущих событиях\"  \n    )  \n]  ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-04T23:17:04.109386Z","iopub.execute_input":"2025-02-04T23:17:04.109741Z","iopub.status.idle":"2025-02-04T23:17:04.116888Z","shell.execute_reply.started":"2025-02-04T23:17:04.109709Z","shell.execute_reply":"2025-02-04T23:17:04.115566Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"5. Инициализация агента","metadata":{}},{"cell_type":"code","source":"agent = initialize_agent(  \n    tools,  \n    llm,  \n    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,  # Тип агента  \n    verbose=True,  # Подробный вывод  \n    max_iterations=6  # Лимит шагов для избежания бесконечных циклов  \n)  ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-04T23:17:11.592184Z","iopub.execute_input":"2025-02-04T23:17:11.592561Z","iopub.status.idle":"2025-02-04T23:17:11.597553Z","shell.execute_reply.started":"2025-02-04T23:17:11.592529Z","shell.execute_reply":"2025-02-04T23:17:11.596379Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":" 6. Запрос к агенту","metadata":{}},{"cell_type":"code","source":"response = agent(\"Какие последние новости о марсоходе?\")  \nprint(response['output'])  ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-04T23:17:15.727739Z","iopub.execute_input":"2025-02-04T23:17:15.728101Z","iopub.status.idle":"2025-02-04T23:17:16.697994Z","shell.execute_reply.started":"2025-02-04T23:17:15.728068Z","shell.execute_reply":"2025-02-04T23:17:16.696428Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Инструменты в LangChain\n\nLangChain предоставляет различные инструменты для взаимодействия агентов с внешним миром. С их помощью можно создавать кастомных агентов для решения задач: поиск в интернете, ответы на вопросы, выполнение кода. В этом разделе рассмотрим типы инструментов и примеры их использования.\n\n**Google Search и суммаризация текста**\n\nВ этом примере создаются два инструмента:\n\n- Поиск в Google для получения актуальной информации.\n- Суммаризация текста с использованием языковой модели.\n- Импорт библиотек","metadata":{}},{"cell_type":"code","source":"from langchain.llms import OpenAI  \nfrom langchain.agents import Tool  \nfrom langchain.utilities import GoogleSearchAPIWrapper  \nfrom langchain.prompts import PromptTemplate  \nfrom langchain.chains import LLMChain  \nfrom langchain.agents import initialize_agent, AgentType  ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-04T23:17:27.977985Z","iopub.execute_input":"2025-02-04T23:17:27.978339Z","iopub.status.idle":"2025-02-04T23:17:27.983607Z","shell.execute_reply.started":"2025-02-04T23:17:27.978309Z","shell.execute_reply":"2025-02-04T23:17:27.982198Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Создание цепочки для суммаризации","metadata":{}},{"cell_type":"code","source":"llm = OpenAI(model=\"gpt-3.5-turbo-instruct\", temperature=0)  \n\n# Шаблон для суммаризации  \nprompt = PromptTemplate(  \n    input_variables=[\"query\"],  \n    template=\"Напиши краткое содержание следующего текста: {query}\"  \n)  \n\nsummarize_chain = LLMChain(llm=llm, prompt=prompt)  ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-04T23:17:31.365158Z","iopub.execute_input":"2025-02-04T23:17:31.365573Z","iopub.status.idle":"2025-02-04T23:17:31.370941Z","shell.execute_reply.started":"2025-02-04T23:17:31.365535Z","shell.execute_reply":"2025-02-04T23:17:31.369787Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Определение инструментов","metadata":{}},{"cell_type":"code","source":"# Убедитесь, что переменные окружения  \n# GOOGLE_API_KEY и GOOGLE_CSE_ID установлены.  \nsearch = GoogleSearchAPIWrapper()  \n\ntools = [  \n    Tool(  \n        name=\"Search\",  \n        func=search.run,  \n        description=\"поиск актуальной информации о событиях\"  \n    ),  \n    Tool(  \n        name=\"Summarizer\",  \n        func=summarize_chain.run,  \n        description=\"суммаризация текстов\"  \n    )  \n]  ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-04T23:17:34.124288Z","iopub.execute_input":"2025-02-04T23:17:34.124669Z","iopub.status.idle":"2025-02-04T23:17:34.138660Z","shell.execute_reply.started":"2025-02-04T23:17:34.124641Z","shell.execute_reply":"2025-02-04T23:17:34.137564Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Инициализация агента","metadata":{}},{"cell_type":"code","source":"agent = initialize_agent(  \n    tools,  \n    llm,  \n    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,  # Тип агента  \n    verbose=True  # Подробный вывод  \n)  ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-04T23:17:36.476095Z","iopub.execute_input":"2025-02-04T23:17:36.476490Z","iopub.status.idle":"2025-02-04T23:17:36.481735Z","shell.execute_reply.started":"2025-02-04T23:17:36.476457Z","shell.execute_reply":"2025-02-04T23:17:36.480542Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Запуск агента","metadata":{}},{"cell_type":"code","source":"response = agent(\"Какие последние новости о марсоходе? Пожалуйста, сделай краткий обзор.\")  \nprint(response['output'])  ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-04T23:17:38.363073Z","iopub.execute_input":"2025-02-04T23:17:38.363469Z","iopub.status.idle":"2025-02-04T23:17:39.989850Z","shell.execute_reply.started":"2025-02-04T23:17:38.363431Z","shell.execute_reply":"2025-02-04T23:17:39.988424Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Пример работы агента:\n\n- Поиск новостей с помощью инструмента Search.\n- Суммаризация результатов через инструмент Summarizer.\n\nДругие инструменты LangChain\n\n- SerpAPI: Интеграция с поисковой системой для получения данных.\n- PythonREPLTool: Выполнение Python-кода внутри агента.\n- Кастомные инструменты: Создание специализированных функций под свои задачи (см. документацию LangChain).\n\n\nLangChain открывает широкие возможности для разработки интеллектуальных агентов. Освоив базовые концепции (инструменты, цепочки, память), вы сможете создавать сложные AI-приложения. Для углублённого изучения рекомендуем пройти полный курс по LangChain. Удачи в разработке! 🚀","metadata":{}},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}